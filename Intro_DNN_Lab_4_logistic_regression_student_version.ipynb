{"cells":[{"cell_type":"markdown","metadata":{"id":"BsPdgBWQn4Vb"},"source":["<center><img src='https://drive.google.com/uc?id=1_utx_ZGclmCwNttSe40kYA6VHzNocdET' height=\"60\"></center>\n","\n","AI TECH - Akademia Innowacyjnych Zastosowań Technologii Cyfrowych. Programu Operacyjnego Polska Cyfrowa na lata 2014-2020\n","<hr>\n","\n","<center><img src='https://drive.google.com/uc?id=1BXZ0u3562N_MqCLcekI-Ens77Kk4LpPm'></center>\n","\n","<center>\n","Projekt współfinansowany ze środków Unii Europejskiej w ramach Europejskiego Funduszu Rozwoju Regionalnego\n","Program Operacyjny Polska Cyfrowa na lata 2014-2020,\n","Oś Priorytetowa nr 3 \"Cyfrowe kompetencje społeczeństwa\" Działanie  nr 3.2 \"Innowacyjne rozwiązania na rzecz aktywizacji cyfrowej\"\n","Tytuł projektu:  „Akademia Innowacyjnych Zastosowań Technologii Cyfrowych (AI Tech)”\n","    </center>"]},{"cell_type":"markdown","metadata":{"id":"pJ-w7K4eu6SK"},"source":["# Logistic regression\n","\n","In this exercise you will train a logistic regression model via gradient descent in two simple scenarios.\n","\n","The general setup is as follows:\n","* we are given a set of pairs $(x, y)$, where $x \\in R^D$ is a vector of real numbers representing the features, and $y \\in \\{0,1\\}$ is the target,\n","* for a given $x$ we model the probability of $y=1$ by $h(x):=g(w^Tx)$, where $g$ is the sigmoid function: $g(z) = \\frac{1}{1+e^{-z}}$,\n","* to find the right $w$ we will optimize the so called logarithmic loss: $J(w) = -\\frac{1}{n}\\sum_{i=1}^n y_i \\log{h(x_i)} + (1-y_i) \\log{(1-h(x_i))}$,\n","* with the loss function in hand we can improve our guesses iteratively:\n","    * $w_j^{t+1} = w_j^{t} - \\eta \\cdot \\frac{\\partial J(w)}{\\partial w_j}$\n","\n","* we can end the process after some predefined number of epochs (or when the changes are no longer meaningful)."]},{"cell_type":"markdown","metadata":{"id":"xt2z7CdJu6SQ"},"source":["Let's start with the simplest example - linear separated points on a plane."]},{"cell_type":"markdown","metadata":{"id":"af367727"},"source":["The formula for the partial derivative of the logistic loss function $J(w)$ with respect to a weight $w_j$ is:\n","\n","$$ \\frac{\\partial J(w)}{\\partial w_j} = \\frac{1}{n} \\sum_{i=1}^n (h(x_i) - y_i) x_{ij} $$\n","\n","where:\n","- $n$ is the number of training examples\n","- $h(x_i)$ is the predicted probability for the i-th example ($h(x_i) = g(w^Tx_i)$)\n","- $y_i$ is the true target for the i-th example\n","- $x_{ij}$ is the j-th feature of the i-th example\n","\n","This formula can be vectorized as:\n","\n","$$ \\nabla J(w) = \\frac{1}{n} X^T (h(X) - y) $$\n","\n","where:\n","- $X$ is the matrix of features (with a column of ones for the bias term)\n","- $y$ is the vector of true targets\n","- $h(X)$ is the vector of predicted probabilities for all examples"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Wg_d38Fou6SU","executionInfo":{"status":"ok","timestamp":1761153229714,"user_tz":-120,"elapsed":65,"user":{"displayName":"Veronika Nechaieva","userId":"13541061591014079018"}}},"outputs":[],"source":["import numpy as np\n","\n","np.random.seed(123)\n","\n","# these parametrize the line\n","a = 0.3\n","b = -0.2\n","c = 0.001\n","\n","# ax + by + c = 0\n","# y = a/b x - b / c\n","\n","# True/False mapping\n","def lin_rule(point, noise=0.):\n","    '''\n","    Returns whether the point is above or below the line.\n","    > 0: left of the line, < 0: below it.\n","    '''\n","    return a * point[0] + b * point[1] + c + noise < 0.\n","\n","# Just for plotting\n","def get_y_of_x_fun(a, b, c):\n","    def y(x):\n","        return - x * a / b - c / b\n","    return y\n","\n","lin_fun = get_y_of_x_fun(a, b, c)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"ZZEHHKP8u6Si","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761153229747,"user_tz":-120,"elapsed":6,"user":{"displayName":"Veronika Nechaieva","userId":"13541061591014079018"}},"outputId":"e876539d-212b-4a2a-d98a-876dbe7a5429"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0.39293837 -0.42772133]\n"," [-0.54629709  0.10262954]\n"," [ 0.43893794 -0.15378708]\n"," [ 0.9615284   0.36965948]\n"," [-0.0381362  -0.21576496]\n"," [-0.31364397  0.45809941]\n"," [-0.12285551 -0.88064421]\n"," [-0.20391149  0.47599081]\n"," [-0.63501654 -0.64909649]\n"," [ 0.06310275  0.06365517]]\n","[np.False_, np.True_, np.False_, np.False_, np.False_, np.True_, np.False_, np.True_, np.True_, np.False_]\n"]}],"source":["# Generate the training data\n","\n","n = 500\n","range_points = 1\n","sigma = 0.05\n","\n","X = range_points * 2 * (np.random.rand(n, 2) - 0.5)\n","y = [lin_rule(x, sigma * np.random.normal()) for x in X]\n","\n","print(X[:10])\n","print(y[:10])"]},{"cell_type":"markdown","metadata":{"id":"CoTCKl3Yu6St"},"source":["Let's plot the data."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"qc99EecDu6Sw","colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"status":"ok","timestamp":1761153236086,"user_tz":-120,"elapsed":6326,"user":{"displayName":"Veronika Nechaieva","userId":"13541061591014079018"}},"outputId":"7abb3ee0-c611-42e7-bb6b-f4174a853070"},"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"18d6c3ed-8ddb-4e3c-9280-d0f62b0deb81\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"18d6c3ed-8ddb-4e3c-9280-d0f62b0deb81\")) {                    Plotly.newPlot(                        \"18d6c3ed-8ddb-4e3c-9280-d0f62b0deb81\",                        [{\"hovertemplate\":\"color=False\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"False\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"False\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0.3929383711957233,0.43893793957112615,0.961528396769231,-0.03813619703127813,-0.12285551064075118,0.06310274768367674,0.4489106497212705,0.4448867651404431,-0.2764226887553718,-0.1382744733407124,-0.14833941940834405,0.8883200364077593,0.24790590358422238,0.7326183157667319,0.20612025682185475,0.7509136835903498,0.33862756592454457,0.6846848752405146,0.5273656828866764,0.1135703847885774,0.10876649943554417,0.8502649792279722,-0.2852048666336475,0.6930124505414441,0.7089049750490095,0.1571029362176659,0.8106831513232198,0.8038227453213411,0.6139373682743583,0.46214607168911415,0.9670432184071112,-0.1433054505981015,0.8551684803042949,0.4837243036840746,0.41739479088549203,0.330522930699366,0.3926225364708127,0.13128400245176564,0.5014340006863358,0.5032879775858368,0.7187781513612228,0.8197433192204178,0.12443675746181126,0.8638642961533562,-0.05417399552308977,0.08527185157701189,0.5387946741479246,0.3223357346558622,0.5845986036891813,0.6910659931251375,0.836794935611266,-0.37266209989574506,-0.5166287255092044,0.7899565757720233,0.9766570692447749,0.9260089319845164,0.5978454664300263,0.43120255030860966,0.004142200653485695,0.9860665221895835,-0.25141563530910394,0.0677719633965892,0.19486621672075,0.26410098960345585,0.7751869209355498,0.9420922810202579,0.6654323945664253,0.13620642763795687,0.11206950753029377,0.8549099971253036,-0.26141765114270443,0.8753367135811916,0.7645522023932325,0.41924645711819575,-0.15491329378388374,0.20586439341384644,0.12914068519228716,0.35381171930552124,0.11947579128942376,0.08597756509038712,0.824264242955258,0.555538035109415,0.641148439355772,0.5595333241778904,0.37674868644125814,0.3500702538187437,0.8887310792371803,-0.08745880191687427,0.8657832962829632,0.8194293240866761,0.41423012053535224,-0.11155787734403955,0.8942390798148665,0.01880345470044764,0.9005032501383015,0.9747021956607815,0.31184620577694955,-0.202721840633721,0.9076368066289529,0.2504170662776031,-0.1529639020468141,0.7366294203448918,0.7289605551472109,0.04697509665003685,0.8864011169543056,-0.065339453974258,0.3043077475858831,0.5491604090411473,-0.3009629452160867,0.9978368119455951,0.2916450433662243,0.5204205158380082,0.46520243458585675,0.6210269125407417,0.8051130771977377,0.7654259693947552,0.7030961027743505,0.787730735747278,-0.14780868925485113,0.8336975705455523,0.6080527366669555,0.8447647091830737,0.2343721771065359,0.9849568718502131,0.5584905857189606,0.23201295513329367,0.32233754359396105,0.4541599010066606,0.2558436977912,0.13514832511056252,-0.22851303512656496,0.29486502601746456,0.5200916134872902,0.7515424210877057,0.5912091772816546,-0.11624145706828282,0.7048990895479752,0.466255790805163,0.4347082677834635,0.5853027214529491,-0.19442566143151208,0.051423082540295706,0.3267855145552814,0.4027196020364654,0.9198782674489336,-0.08563654460746806,-0.24664600548731452,0.333054237989985,0.8176835922566612,0.9622355465549557,0.7612142843531859,0.3126863919588634,-0.3460636283540708,-0.06638024507604268,0.31753521208333435,0.889555664421255,0.6025535682370515,-0.45154997708390954,0.6172522294510006,0.5293284303672616,0.315334886150316,0.9049777355789272,0.6076866322378518,0.5403383479873858,0.6881549255008828,0.8100569157181015,0.991563500270561,0.8904732698901685,0.45408548789275915,0.7582848767790669,0.0023795615853585694,0.3361454746572943,0.7974253848648161,-0.6078319067420002,0.7198822965652938,0.3260855713669526,-0.4426250598639063,0.4946518118748289,0.5379173899297283,0.5121200582593213,0.7955054884080741,0.8307090132509833,0.51094878283622,0.8729437059493887,0.6553100519377695,-0.46980742263631026,0.9758722062002887,0.7987832098780736,0.8951636702748942,0.36965170022129956,-0.3501807100483485,0.0895267419832586,0.8438397232578121,0.379905094490139,0.6570546443890612,0.006494854165009167,0.2940391902734172,-0.5404728053009697,0.9197991276516209,0.5032299257299866,0.9597726158347755,-0.5204610568571193,0.5711135100025049,0.9040214499383878,0.1928079257196269,0.30950528890783247,0.6847749921272204,-0.04316830334205135,0.23970215494015235,0.5172492951116259,0.8063554445217347,0.32527283734041434,-0.299720735994095,-0.23265450165228518,0.7928513430704796,0.9350021197655862,0.40174267993363544,0.7410912412270689,0.7897555822776656,-0.09254474659989875,0.07028280003043341,-0.684932807794727,-0.10129624337267717,0.9731597782009065,-0.2357816140977369,-0.1466553320947228,0.6419378954917552,0.47984544390359596,0.5090458128098267,0.16224601776236014,0.7791174466178084,0.9880090778688706,-0.037769969738526754,-0.0050582018792098005,-0.09330772621944505,0.1892438384218078,0.04098747731455665,0.2794421861721639,0.9087566136178864,-0.07328447285057083,0.07731648257763846,0.2681696104943474,0.3818307778445251],\"xaxis\":\"x\",\"y\":[-0.42772133009924107,-0.15378707975107808,0.3696594771697266,-0.21576496361169895,-0.8806442067808633,0.06365517419373212,0.22204702135516574,-0.3540821722936436,-0.5434735382420888,-0.01262980469938757,-0.37547755405506944,0.0036733517686731165,-0.7687632098414086,-0.4990892692069866,0.09013601293292983,0.02084467495602227,0.17187310512442577,-0.8336100233351225,-0.512667250926252,-0.6820807117105545,-0.2220988517537108,0.6833399938254325,-0.9128170724019189,0.1065146895934268,-0.23032437744847778,0.0430661187946646,-0.584728277607351,0.9672617698234465,-0.2112598920944504,-0.6778619711415703,-0.8412684192439686,-0.5909142809071446,0.13800746286039067,-0.9028419343114624,0.6784866956101672,-0.7772156567845685,-0.11934424666918186,-0.8301916736163648,0.14812765029992891,-0.8417020785235896,0.6430082264011159,-0.74273760498124,-0.7555129007349899,0.1643509182917402,-0.7564912890538926,-0.8664511135499906,0.14754822731764894,-0.9018057387544474,0.037433181781010294,-0.6261925021465693,-0.8174073155935964,-0.905320925524526,-0.8089407168892782,-0.9135542158407064,-0.2496289450344038,-0.31633877286996714,0.5976926624261238,-0.17896042917214428,-0.8651027297398965,-0.5270752076039422,-0.5719761701833075,-0.6759683258989382,-0.4136950627456413,-0.9476067894983125,-0.9677627391532522,0.7433658662846145,0.6921096763929282,-0.5490732793880801,0.0011228416982023148,-0.6032686219465617,-0.5155603870154655,0.8160221673260801,0.6446076294474508,0.9186904505177937,-0.5099339228886475,-0.2716251004871062,-0.6173285585588868,-0.5689891054486804,-0.3303271742659615,0.3879694057164851,0.16142642678890784,-0.599197370074692,-0.07013029055434705,-0.5250435600234682,-0.5913917643031346,-0.9879442286934041,-0.01761903805083298,-0.4403959631284595,-0.3712972927416065,-0.9131638180594459,-0.032221921930747355,-0.9273533112960368,0.23531995422938223,-0.4061969678862889,0.6319321793341197,-0.18267973250844394,-0.1886936030975439,-0.6302279379493827,-0.7942402292376849,-0.11660522390755879,-0.25601643415144104,-0.4390460387063806,-0.4461964199079942,-0.7818236054713659,-0.5097388168770756,-0.24978170380496256,-0.5340402066357874,-0.73077300532706,-0.4451520799852293,-0.9187677508830809,-0.9226008299755113,-0.5398200850034183,0.3561906298376878,-0.7377697896946063,-0.5556858750298028,0.8389449326552252,-0.7447755515639585,-0.006984055249773746,-0.3887072238137632,0.035246921522578134,0.7153035745620648,-0.3932385319338476,-0.19052102805250493,-0.8022974308820272,0.04578400177043562,-0.8821210427939581,-0.24326125860953218,0.34225320894024347,-0.9233367859629227,-0.6483434690886098,-0.5027524649772885,-0.9252157824551213,0.05388127746874183,0.04143663984269974,-0.0160479022841038,-0.36313043724501304,0.912624055579403,0.21045367189156106,0.43150082284966573,-0.514075626979992,-0.7563209444651771,-0.10750326945933697,0.09882611756490323,0.41516223711871203,0.7534093630076226,-0.5541075266644941,-0.7922315350706677,-0.6159397125720649,-0.6759983183760787,0.5014950502588418,-0.2173670149654856,0.2947702911466872,-0.6412196506906682,-0.4734379273866818,-0.6079810685088323,0.24265675085586236,0.7509196586260745,-0.76605897246725,-0.6704412788210139,0.6206296905208952,0.16980853264299123,-0.002684640999628618,-0.23525957516249663,-0.11907599582429196,-0.8475918719012951,-0.11280739610818502,-0.5603280999974256,-0.4198271499032389,-0.9699677031658085,-0.8721229017707841,-0.5813320185332611,-0.6547765156541978,0.24198273500095713,-0.945318437361091,-0.7929581497016847,0.42015044891594,-0.8600356212302407,-0.5808160817704386,0.23752355638547384,0.07415958760068819,0.8941349809805563,0.5090366801200439,0.0896264988152331,-0.5528407395766171,-0.2965932940445908,-0.7452230554764747,0.6706862017605328,0.027358652020814223,0.6823277315382719,-0.0277766645604669,-0.7995710753303567,-0.3059496938662061,0.10105938091740607,-0.13138187068166007,-0.26546887403416486,-0.30221415193250145,-0.5005075933777479,-0.6073071107504768,-0.014172544762853123,-0.052016237338676774,0.33686624835824386,-0.9696046816724502,-0.821808064173168,0.05491335476625525,-0.1898864573853314,-0.7965078980367526,0.2283448078022614,-0.5334128602243893,-0.3414417330254145,0.4375316709583503,-0.261922267923796,0.11573980183678279,-0.6092953068857829,-0.878520754103103,-0.553459051292871,-0.7749198276633908,-0.08333497465404838,0.388772200337151,0.5064087065469591,-0.9567062742938683,-0.15405353257147225,-0.7618606032261386,-0.920173892907501,-0.24375813738615282,-0.8977473989266265,-0.9685091253735165,-0.08235784013480707,0.47658747428943604,-0.29666124763292956,-0.2713166408505816,-0.09531897995523031,-0.27220610301298875,-0.10157510240756351,-0.30819137928495066,-0.19069732863807065,-0.9661033708197893,-0.5214135079468387,-0.3696764508811845,-0.8263963554954437,-0.8832261926827509,-0.7079285260311046,-0.4712050750197576,-0.30570788066254195],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"color=True\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"True\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"True\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[-0.5462970928715938,-0.3136439676982612,-0.20391148933913716,-0.635016539093,0.2688019171026421,-0.41257190722234127,-0.8157901201098496,-0.14729738607438358,-0.3654290363593582,-0.0339314714745913,0.03897023851961867,-0.7587426680193525,-0.3144723324513832,-0.1659555779505968,0.24980700419119972,-0.6115540788424583,-0.8085749667752258,0.25449794410253745,-0.9677415866099663,-0.6938589697504538,-0.3624671472362473,-0.3904638531778051,0.4099176609027244,-0.2881702685650809,0.18635383312444231,-0.6977450953038395,-0.518288204552751,0.026256308398004302,-0.7881830298863723,-0.3560387870633839,-0.36642420576324053,-0.6578363415898019,-0.3226583081713468,-0.9946238708513586,-0.4150211744151504,-0.4849158716918338,0.20139713566717976,-0.09872701896253044,-0.8133465792603585,-0.08517600495277611,-0.6681242315860922,-0.4269267665417962,0.32974489760658865,-0.12357123124555058,0.1653421757228093,-0.32586723310478005,-0.8364398258120296,-0.20124257979439975,-0.5972009972372583,-0.0640248518865012,-0.9851472429107739,-0.5878085451094517,-0.24202830060216463,-0.9413605542124575,-0.935604130124152,0.30672974270608133,-0.7947294815784083,-0.1482646116001618,-0.1768615535823257,-0.6367423146523508,-0.16541787819331177,-0.5268003765889613,-0.07269455022896798,-0.5235001885751764,-0.396106327474562,0.07900964510747066,-0.9889091831861909,-0.8059236827222775,-0.5835034065221267,-0.6179860892591578,0.3015007329525867,-0.9495152844007126,-0.7891082677890984,-0.3987797289935906,-0.43753043709418304,-0.9881143125529404,-0.7460839379280773,-0.9082095355956588,0.42032330264139706,-0.14037332422683613,-0.2880846640527708,-0.7024446875157928,-0.7521539801521113,-0.9672150382481373,-0.9845249717481921,-0.5490031790999528,-0.2728473640247733,0.14429353596892236,-0.40350921336534107,-0.09382215090773993,0.1749874949590049,-0.9929355780675033,-0.8958177312210023,-0.255207038811776,-0.9467777688800809,0.36180599798991286,0.21505814164127757,-0.3289122529214277,-0.22025153934341524,-0.3024053678260179,-0.4523155766938485,-0.32732094200641115,-0.7652031256170215,-0.7094725320590924,-0.44395281251192786,-0.5346272422142382,-0.3348394605646472,0.31563014629961006,-0.05862250310691475,-0.8251845146943544,-0.4596474651393325,-0.5786947448918736,-0.5639291209010509,-0.9186336190172377,-0.26225031663814624,-0.587736927429545,-0.2763654689372832,-0.3540521143951476,-0.4853037885188578,-0.4727793077643361,-0.9588476852127534,-0.8131458624778485,-0.17946856486153395,-0.9736803374182772,0.4187713848063441,0.0857208493548085,-0.6688800585425743,-0.5224331877147377,-0.820336265855272,-0.8961981057315855,-0.09782330756024993,0.22435872338118368,-0.9998362247726647,-0.1689928983247333,-0.5743370028617019,-0.32037829191131073,-0.11735172908105773,-0.2048718967330272,-0.5587933643855953,-0.7045543127207596,-0.93209272774356,-0.7286534057498555,-0.5049736929992872,0.0753268881417386,-0.28026530211786604,0.09295804333816982,0.02075274069516797,-0.779789607109199,-0.6650367176738778,-0.9299336629319037,-0.43090160346573914,-0.13406133843314483,0.2963262464115486,0.39588447240618807,-0.9181844139274047,-0.0697040270519731,-0.9449141406956936,-0.06388066522548819,-0.04906442501776742,-0.9366621387038254,-0.4028416312565639,0.07995416586519544,-0.28986974726719494,-0.07772425893566126,-0.32754021046469206,-0.803632002757066,-0.9660170013075136,-0.09202037117469253,-0.7685109281018061,-0.5858999002321339,-0.6733246173272343,-0.544395868369947,0.1752315106376201,0.03754515732795349,-0.7878894788247499,-0.34332924232921846,-0.0377433448397273,-0.47134404137588426,-0.8056807885690616,-0.4570163270730834,-0.3232457775625437,-0.047946784729832714,0.22334275435020556,0.46679079733963813,0.1892871657730495,-0.9128625908945263,0.10190655046651087,-0.4109660118570211,0.03856072228565277,-0.51068042587473,0.12725596606313938,-0.496445858557794,0.0026485326018315103,-0.5073579920175544,-0.44000009786729866,-0.3515567511166282,-0.7729818431814353,0.17180394930667076,-0.13824869573857623,0.10882426313102833,-0.6519358189225593,-0.5883244346333796,-0.5481529185271694,-0.7712303354274521,-0.33883579437010125,-0.6826417130589186,-0.5075141625997477,-0.21780838769908106,-0.2256095901609656,-0.971712388805914,-0.4639577664307677,-0.23361193998716323,-0.6016836853331549,-0.8726182813602585,-0.5585385804194414,-0.8333034605823042,0.7207468205303624,-0.4640356787672526,-0.8376020050004185,-0.1671267751990817,-0.37692766009331913,0.1750803201342339,-0.5626357206505743,-0.21315932654703862,0.2990019113910076,0.3478719336389988,0.40224449932403994,-0.9099208323623311,-0.8033438192301341,-0.9604878188406583,-0.3854906949688557,-0.7976360917896224,0.11559732073043683,-0.14267305532184094,-0.632385255984472,-0.8375983002278224,-0.46375113937743095,0.44432648432935307,0.33600259064460825,-0.5151057961734966,0.04058084262699513,-0.939812733334342,-0.9703188415880246,-0.29544610592204323,-0.20372422902166987,-0.8399869599897418,-0.5000913906601345,-0.31382780607201477,-0.9745248726321878,-0.16717074960590983,0.03648543595415754,-0.5179187855649501,-0.19092290411070478,-0.3475288064790756,-0.9505176926797692,-0.5884049876364068,-0.991663022784848],\"xaxis\":\"x\",\"y\":[0.10262953816578246,0.45809941476808325,0.4759908114640714,-0.6490964877050149,0.6988635881555791,0.2619522477089755,-0.13259765464094353,0.7867783262342696,-0.17034757609273643,0.97111957122141,0.2257890515259353,0.6526816010136665,-0.3917584219456318,0.3626015315855933,0.34937810197564967,0.14491391498294615,0.7706536525502792,0.4468327163799095,0.188863758890085,0.3910590575418218,0.3839405910636393,-0.20362863616403803,0.9907169640680349,0.5250956275708676,0.38340359740035423,-0.2022474145476869,-0.31308797190335014,0.33324910032814326,-0.7382100986718385,0.3231286733324874,-0.291470648816643,0.6582252690037809,0.10474015058814623,0.9766908385656401,0.04002030614496688,0.12871808584956335,0.7317289166065293,0.095527145257708,-0.4062784490386411,0.5070519815962291,0.5619958759999146,-0.38706049334088544,0.7757135853524453,0.5301921904786131,0.6296874057868194,0.855153159150779,-0.7231688544368204,-0.15138627783801617,0.6232886965680431,0.6158764189672203,0.10318545196481099,0.4355151245591151,0.33676789451891964,0.2718007187027123,0.4895613102835319,0.9921726547356509,0.3996681495458294,0.576374347202931,-0.03794744898969293,-0.35736220098714266,0.9780690147905988,0.8336646658776579,0.004432670645574177,0.6155821725803121,0.9611643971885753,0.2526187234197126,-0.030181113114881475,-0.0761824768631032,-0.11326459639757647,0.9349886136128369,0.7309197030457988,-0.46618837041773054,-0.5350404287915285,0.2688845357988783,-0.2754464780468475,-0.2685617481452709,0.5543249231412044,0.4219973871910201,0.9170194860433336,0.7457578286436146,0.8595273058076935,0.880058029856547,0.19297379668347392,0.4423687321012135,-0.8303554451095327,0.7502490677464493,0.07991987042511695,0.32190359005920643,-0.16274628203994812,0.8647013230841631,0.8965047432362825,-0.03822191225007576,-0.18644221305226294,0.7143061157424873,0.8402984595180099,0.8084519881284353,0.6239066248722487,-0.30086754394488047,0.5095941631455665,0.2692761405160946,-0.5877697425728619,-0.3458002147689976,-0.39789328359760034,-0.81562780526326,0.4835208442897536,0.49339526155299307,0.9073942385833056,0.5457556610030836,0.6179277454235701,-0.3064105595728812,-0.27915256109258024,-0.15759988565997474,0.6915050146058555,-0.3344927658761181,0.22395407810981105,-0.6698671143439252,0.7267067030808634,0.9441964904559847,-0.8346946480002635,-0.4570402929805095,0.8361940319182133,0.6749322168674181,0.32343308040461416,-0.9517031884324552,0.8491037695869563,0.7178336751628815,0.22536456561797924,0.4095570951110612,0.29689942381809553,-0.4113861088916877,-0.42579342054900704,0.9764298872549071,0.9611946841239778,0.48923092431346205,-0.21539185783214498,0.19014775269522977,0.8656850652394841,-0.044443903249579364,-0.35468973775269963,-0.4315615309368892,0.9652451703743776,0.1273291857983856,0.049732442905815466,0.43360672826407365,0.5954651903818784,0.7238241908635399,0.5138916730586023,0.6341981574804765,0.06815298443212892,-0.712798062235716,0.9317726249795077,0.7680060653500338,0.7168552925473197,0.6107938707887324,0.032221671063005,-0.13002857807920987,-0.9361640247884973,0.25181302337033773,0.9348732060427549,-0.6965400998875757,0.8836139288325089,0.8634057659229719,0.9082879377969193,0.3697829309531797,0.9917221569015442,0.886361142354166,-0.5489302314470241,-0.26895876344511094,0.9052053968159279,0.3111031013208536,0.9682565760473945,0.17883086626139466,0.9347237712853602,0.5293150761950602,-0.9958161976335451,-0.26389347983378864,-0.06630057957322255,0.8872294898893149,-0.5864337022065811,-0.03156045295712162,0.5482721396009664,0.7407410088869071,0.6950046210562868,0.9892207737353185,0.24829995947578154,0.3680821294140124,0.626627277161993,0.9427279973695071,0.3886297723527157,-0.3228355955400861,0.7733563315790204,0.04776137833498706,0.19425067968048437,-0.22945710798222474,0.3153204821182096,0.5087832098086722,0.5507295256853832,0.6707773742930003,0.24992890641770682,0.9513425327061629,0.8082284337002665,0.30008651358031346,0.7036378208440495,-0.8948393230993814,0.8406608659736798,-0.16015365777784174,-0.5893004505432695,-0.37898251641058756,0.11171916915545177,0.6952939904469551,0.9804780004281579,0.3873107885809939,0.933158751774783,-0.02970122435390654,-0.41205173554437713,-0.6073819897560295,0.9540577001203403,0.3508179754063787,0.4469311836626966,0.8363198365757836,0.8829339948110502,0.16827796227199743,-0.08896071540408657,0.6246524786326983,0.7426526069989299,0.9401970876390056,0.6434414728919529,0.34539702799510086,0.18893423744536708,-0.2688654376284765,0.5022424842472986,0.0323319139438869,0.48960905388078824,0.4655349847972601,-0.8368334191002547,0.6915964472674914,-0.6110043209111486,0.8641774860878215,0.7174532189053289,0.3478559571877169,-0.0026235680087136615,-0.3218015336751907,-0.6735599366208502,0.6041513340779661,0.4543820101211262,-0.7677492470532783,-0.2989213603780245,0.2747134632589292,0.5265372745343033,-0.13552161266069618,0.2465381697122555,0.01687429761628878,0.6530603247147659,-0.033566152501755875,-0.3824982436695592,-0.41868864022069974,-0.41021058196351023],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"name\":\"ground truth border\",\"x\":[-0.9998362247726647,0.9921726547356509],\"y\":[-1.4947543371589969,1.4932589821034759],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"title\":{\"text\":\"color\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('18d6c3ed-8ddb-4e3c-9280-d0f62b0deb81');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}}],"source":["import plotly.express as px\n","\n","# plotly has a problem with coloring boolean values, hence stringify\n","# see https://community.plotly.com/t/plotly-express-scatter-color-not-showing/25962\n","fig = px.scatter(x=X[:, 0], y=X[:, 1], color=list(map(str, y)))\n","x_range = [np.min(X[:, 0]), np.max(X[:, 1])]\n","fig.add_scatter(x=x_range, y=list(map(lin_fun, x_range)), name='ground truth border')\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"vq3J7fZpu6S4"},"source":["Now, let's implement and train a logistic regression model. You should obtain accuracy of at least 96%."]},{"cell_type":"code","source":["import numpy as np\n","X = np.array(X)\n","y = np.array(y)"],"metadata":{"id":"4xaXvF688_Aj","executionInfo":{"status":"ok","timestamp":1761153236094,"user_tz":-120,"elapsed":4,"user":{"displayName":"Veronika Nechaieva","userId":"13541061591014079018"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Generate the training data\n","\n","print(n, X.shape, y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mNjq1VLb824J","executionInfo":{"status":"ok","timestamp":1761153236116,"user_tz":-120,"elapsed":19,"user":{"displayName":"Veronika Nechaieva","userId":"13541061591014079018"}},"outputId":"89cb627a-3ad9-47bd-f4b5-9347ab3038bd"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["500 (500, 2) (500,)\n"]}]},{"cell_type":"code","source":["def sigmoid(x: np.array) -> np.array:\n","  return 1 / (1 + np.e ** -x)\n","sigmoid(np.array([-3, -2, -1, 0, 1,2,3]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B9br8z4--v-k","executionInfo":{"status":"ok","timestamp":1761153236130,"user_tz":-120,"elapsed":11,"user":{"displayName":"Veronika Nechaieva","userId":"13541061591014079018"}},"outputId":"71d91f33-82e8-458b-e740-d36a617b162a"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.04742587, 0.11920292, 0.26894142, 0.5       , 0.73105858,\n","       0.88079708, 0.95257413])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["def h(w_j:np.array, x: np.array) -> np.array:\n","  print(\"x,w:\", x.shape, w_j.shape)\n","  print(\"h:\", (np.dot(x, w_j.reshape(1,))).shape)\n","  return sigmoid(np.dot(x, w_j.T))\n","\n","# def logloss(w_j: np.array, x: np.array, b, y: np.array) -> np.float32:\n","#   # print(y * np.log(h(w_j, x)))\n","#   # print((1-y) * np.log(1 - h(w_j, x)))\n","#   # print(y * np.log(h(w_j, x)) + (1-y) * np.log(1 - h(w_j, x)))\n","#   # print(np.sum(y * np.log(h(w_j, x)) + (1-y) * np.log(1 - h(w_j, x))))\n","#   # print( - 1/n * np.sum(y * np.log(h(w_j, x)) + (1-y) * np.log(1 - h(w_j, x))))\n","#   return - 1/n * np.sum(y * np.log(g(w_j, x, b)) + (1-y) * np.log(1 - g(w_j, x,b)))\n","\n","print(logloss(np.array([1,2, 2.9]), np.array([[1,3], [2,4], [2,3]], dtype=np.int32), np.array([1, 1.8, 3])))\n","# print(logloss(np.array([1.2,0,1.6,2,1.1,0,0.9]), np.array([-3, -2, -1, 0, 1,2,3]), np.array([-3, -3, -1, 0.1, 2,2,3])))\n","# print(logloss(np.array([1.2,0,1.6,2,1.1,0,0.9]), np.array([-3, -2, -1, 0, 1,2,3]), np.array([-4, -3, -1, 1, 20,2,3])))\n","# print(logloss(np.array([1.2,0,1.6,2,1.1,0,0.9]), np.array([-3, -2, -1, 0, 1,2,3]), np.array([-3, 18, -1.2, 100, 20,20,-30])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"_9l_57Yd_0E9","executionInfo":{"status":"error","timestamp":1761154992737,"user_tz":-120,"elapsed":40,"user":{"displayName":"Veronika Nechaieva","userId":"13541061591014079018"}},"outputId":"8e4f02cc-043f-4ccf-aa97-2d39631e025b"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["x,w: (3, 2) (3,)\n"]},{"output_type":"error","ename":"ValueError","evalue":"shapes (3,2) and (3,) not aligned: 2 (dim 1) != 3 (dim 0)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-7164030.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m# print(logloss(np.array([1.2,0,1.6,2,1.1,0,0.9]), np.array([-3, -2, -1, 0, 1,2,3]), np.array([-3, -3, -1, 0.1, 2,2,3])))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# print(logloss(np.array([1.2,0,1.6,2,1.1,0,0.9]), np.array([-3, -2, -1, 0, 1,2,3]), np.array([-4, -3, -1, 1, 20,2,3])))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-7164030.py\u001b[0m in \u001b[0;36mlogloss\u001b[0;34m(w_j, x, y)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;31m# print(np.sum(y * np.log(h(w_j, x)) + (1-y) * np.log(1 - h(w_j, x))))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;31m# print( - 1/n * np.sum(y * np.log(h(w_j, x)) + (1-y) * np.log(1 - h(w_j, x))))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-7164030.py\u001b[0m in \u001b[0;36mh\u001b[0;34m(w_j, x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_j\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x,w:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"h:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: shapes (3,2) and (3,) not aligned: 2 (dim 1) != 3 (dim 0)"]}]},{"cell_type":"markdown","metadata":{"id":"mdf9zB0L8F0U"},"source":["Reminder:\n","\n","* we are given a set of pairs $(x, y)$, where $x \\in R^D$ is a vector of real numbers representing the features, and $y \\in \\{0,1\\}$ is the target,\n","* for a given $x$ we model the probability of $y=1$ by $h(x):=g(w^Tx)$, where $g$ is the sigmoid function: $g(z) = \\frac{1}{1+e^{-z}}$,\n","* to find the right $w$ we will optimize the so called logarithmic loss: $J(w) = -\\frac{1}{n}\\sum_{i=1}^n y_i \\log{h(x_i)} + (1-y_i) \\log{(1-h(x_i))}$,\n","* with the loss function in hand we can improve our guesses iteratively:\n","    * $w_j^{t+1} = w_j^{t} - \\eta \\cdot \\frac{\\partial J(w)}{\\partial w_j}$\n","\n","* we can end the process after some predefined number of epochs (or when the changes are no longer meaningful)."]},{"cell_type":"code","execution_count":47,"metadata":{"id":"Lw-eg0x0u6S6","colab":{"base_uri":"https://localhost:8080/","height":384},"executionInfo":{"status":"error","timestamp":1761155291078,"user_tz":-120,"elapsed":80,"user":{"displayName":"Veronika Nechaieva","userId":"13541061591014079018"}},"outputId":"384f144a-1e0a-4672-c8f8-2657638badb3"},"outputs":[{"output_type":"stream","name":"stdout","text":["shapes in f: (2,) (500, 2)\n","(500,)\n","(500, 2) (500,) (500,)\n"]},{"output_type":"error","ename":"ValueError","evalue":"cannot reshape array of size 1000 into shape (500,)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-196083619.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m#############################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m### YOUR CODE BEGINS HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-196083619.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(w, b, x, y)\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0mw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# comes from jacobian of logloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m   \u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1000 into shape (500,)"]}],"source":["################################################################\n","# TODO: Implement logistic regression and compute its accuracy #\n","################################################################\n","\n","w = np.random.random(size = (2))\n","b = 12\n","lr = 0.5 # step size\n","\n","n_epochs = 40\n","losses = []\n","\n","def ground_truth(points):\n","    return np.array([lin_rule(point) for point in points])\n","\n","def predict(w, points, bias):\n","  return g(w, points, bias) > 0.5\n","\n","def f(w, x, b):\n","  print(\"shapes in f:\", w.shape, x.shape)\n","  print((np.dot(x, w.T) + b).shape)\n","  return np.dot(x, w.T) + b\n","\n","def g(w, x, b):\n","  return sigmoid(f(w, x, b))\n","\n","def logloss(w_j: np.array, x: np.array, b, y: np.array) -> np.float32:\n","  return - 1/n * np.sum(y * np.log(g(w_j, x, b)) + (1-y) * np.log(1 - g(w_j, x,b)))\n","\n","def update(w, b, x, y):\n","  prediction = g(w,x,b)\n","  print(x.shape, prediction.shape, y.shape)\n","  w1 = w - (lr * 1/n * x * (prediction - y).reshape((n,1))).reshape((n,)) # comes from jacobian of logloss\n","  b1 = b - (lr * 1/n * 1 * (prediction - y).reshape((n,1))).reshape((n,))\n","  return w1, b1\n","\n","for i in range(n_epochs):\n","    #############################\n","    # TODO: Fill in the details #\n","    #############################\n","    ### YOUR CODE BEGINS HERE ###\n","    w, b = update(w, b, X, y)\n","    loss = logloss(w, X, b, y)\n","    losses.append(loss)\n","\n","    print(f'Iter: {i:>3} Loss: {loss:8.8f} w[:5]: {w[:5]}')\n","    print(\"Accuracy:\", np.sum(predict(w, X, b) == y) / n)"]},{"cell_type":"markdown","metadata":{"id":"BextVVMWu6TB"},"source":["Let's visually asses our model. We can do this by using our estimates for $a,b,c$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"odWHQD9Au6TE","executionInfo":{"status":"aborted","timestamp":1761153236145,"user_tz":-120,"elapsed":6661,"user":{"displayName":"Veronika Nechaieva","userId":"13541061591014079018"}}},"outputs":[],"source":["#################################################################\n","# TODO: Pass your estimates for a,b,c to the get_y_fun function #\n","#################################################################\n","lin_fun2 = get_y_fun(...)\n","\n","fig = px.scatter(x=X[:, 0], y=X[:, 1], color=list(map(str, y)))\n","x_range = [np.min(X[:, 0]), np.max(X[:, 1])]\n","fig.add_scatter(x=x_range, y=list(map(lin_fun, x_range)), name='ground truth border')\n","fig.add_scatter(x=x_range, y=list(map(lin_fun2, x_range)), name='estimated border')\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"u43DFWVFu6TO"},"source":["Let's now complicate the things a little bit and make our next problem nonlinear."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qNCns_WIu6TS","executionInfo":{"status":"aborted","timestamp":1761153236147,"user_tz":-120,"elapsed":6662,"user":{"displayName":"Veronika Nechaieva","userId":"13541061591014079018"}}},"outputs":[],"source":["# Parameters of the ellipse\n","s1 = 1.\n","s2 = 2.\n","r = 0.75\n","m1 = 0.15\n","m2 = 0.125\n","\n","# 0/1 mapping, checks whether we are inside the ellipse\n","def circle_rule(x, y, noise=0.):\n","    return 1 if s1 * (x - m1) ** 2 + s2 * (y - m2) ** 2 + noise < r ** 2 else 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H91RdYcOu6Tb","executionInfo":{"status":"aborted","timestamp":1761153236201,"user_tz":-120,"elapsed":6716,"user":{"displayName":"Veronika Nechaieva","userId":"13541061591014079018"}}},"outputs":[],"source":["# Training data\n","\n","n = 500\n","range_points = 1\n","\n","sigma = 0.1\n","\n","X = range_points * 2 * (np.random.rand(n, 2) - 0.5)\n","\n","y = [circle_rule(x, y, sigma * np.random.normal()) for x, y in X]\n","\n","print(X[:10])\n","print(y[:10])"]},{"cell_type":"markdown","metadata":{"id":"1keKZp-su6Tl"},"source":["Let's plot the data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_5qQnZLBu6Tr","executionInfo":{"status":"aborted","timestamp":1761153236202,"user_tz":-120,"elapsed":6716,"user":{"displayName":"Veronika Nechaieva","userId":"13541061591014079018"}}},"outputs":[],"source":["import plotly.graph_objects as go\n","\n","fig = px.scatter(x=X[:, 0], y=X[:, 1], color=list(map(str, y)))\n","\n","xgrid = np.arange(np.min(X[:, 0]), np.max(X[:, 0]), 0.003)\n","ygrid = np.arange(np.min(X[:, 1]), np.max(X[:, 1]), 0.003)\n","contour =  go.Contour(\n","        z=np.vectorize(circle_rule)(*np.meshgrid(xgrid, ygrid, indexing=\"ij\")),\n","        x=xgrid,\n","        y=ygrid\n","    )\n","fig.add_trace(contour)\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"qMwKzVQZu6Tw"},"source":["Now, let's train a logistic regression model to tackle this problem. Note that we now need a nonlinear decision boundary. You should obtain accuracy of at least 90%."]},{"cell_type":"markdown","metadata":{"id":"Kcnc848fu6Tx"},"source":["Hint:\n","<sub><sup><sub><sup><sub><sup>\n","Use feature engineering.\n","</sup></sub></sup></sub></sup></sub>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cPINtZzou6T0","executionInfo":{"status":"aborted","timestamp":1761153236204,"user_tz":-120,"elapsed":6717,"user":{"displayName":"Veronika Nechaieva","userId":"13541061591014079018"}}},"outputs":[],"source":["################################################################\n","# TODO: Implement logistic regression and compute its accuracy #\n","################################################################"]},{"cell_type":"markdown","metadata":{"id":"8nYLJvI4u6T7"},"source":["Let's visually asses our model.\n","\n","Contrary to the previous scenario, converting our weights to parameters of the ground truth curve may not be straightforward. It's easier to just provide predictions for a set of points in $R^2$."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8vn13Nfuu6T9","executionInfo":{"status":"aborted","timestamp":1761153236211,"user_tz":-120,"elapsed":6724,"user":{"displayName":"Veronika Nechaieva","userId":"13541061591014079018"}}},"outputs":[],"source":["h = .02\n","\n","xgrid = np.arange(np.min(X[:, 0]), np.max(X[:, 0]), h)\n","ygrid = np.arange(np.min(X[:, 1]), np.max(X[:, 1]), h)\n","\n","xx, yy = np.meshgrid(xgrid, ygrid, indexing=\"ij\")\n","X_plot = np.c_[xx.ravel(), yy.ravel()]\n","\n","print(X_plot.shape)\n","\n","_X = np.concatenate([X_plot, X_plot**2], axis=1)\n","\n","preds = logistic_regression(_w, _b, _X)\n","print(preds.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cE_jWcRZu6UG","executionInfo":{"status":"aborted","timestamp":1761153236213,"user_tz":-120,"elapsed":6725,"user":{"displayName":"Veronika Nechaieva","userId":"13541061591014079018"}}},"outputs":[],"source":["fig = px.scatter(x=X[:, 0], y=X[:, 1], color=list(map(str, y)))\n","\n","xx, yy = np.meshgrid(xgrid, ygrid, indexing=\"ij\")\n","\n","contour = go.Contour(z=preds.reshape(len(xgrid), len(ygrid)), x=xgrid, y=ygrid)\n","fig.add_trace(contour)\n","fig.show()"]},{"cell_type":"markdown","metadata":{"id":"hrr0piFgn9jz"},"source":["<center><img src='https://drive.google.com/uc?id=1BXZ0u3562N_MqCLcekI-Ens77Kk4LpPm'></center>"]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/mim-ml-teaching/public-dnn-2025-26/blob/main/docs/Lab_4_logistic_regression_student_version.ipynb","timestamp":1761066492840}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}