{"cells":[{"cell_type":"markdown","metadata":{"id":"yt6ZsxXC-Enh","jukit_cell_id":"3bbXhEGl0p"},"source":["<center><img src='https://drive.google.com/uc?id=1_utx_ZGclmCwNttSe40kYA6VHzNocdET' height=\"60\"></center>\n","\n","AI TECH - Akademia Innowacyjnych Zastosowań Technologii Cyfrowych. Program Operacyjny Polska Cyfrowa na lata 2014-2020\n","<hr>\n","\n","<center><img src='https://drive.google.com/uc?id=1BXZ0u3562N_MqCLcekI-Ens77Kk4LpPm'></center>\n","\n","<center>\n","Projekt współfinansowany ze środków Unii Europejskiej w ramach Europejskiego Funduszu Rozwoju Regionalnego\n","Program Operacyjny Polska Cyfrowa na lata 2014-2020,\n","Oś Priorytetowa nr 3 \"Cyfrowe kompetencje społeczeństwa\" Działanie  nr 3.2 \"Innowacyjne rozwiązania na rzecz aktywizacji cyfrowej\"\n","Tytuł projektu:  „Akademia Innowacyjnych Zastosowań Technologii Cyfrowych (AI Tech)”\n","    </center>"]},{"cell_type":"markdown","metadata":{"id":"4ykx6csq-Enk","jukit_cell_id":"MjFPoyxoBk"},"source":["# Latent Space Classifier\n","\n","\n","In this task, you will:\n","* train a Variational AutoEncoder on MNIST (the code is already prepared and ready)\n","* train a digit classifier on the latent space of the Variational AutoEncoder\n","\n","## Variational AutoEncoder - review\n","Below is a quick reminder on the Variational AutoEncoder:\n","\n","* Let $P^*$ be the true data distribution. We have some samples from this.\n","* Let $p(z)$ be a *prior* distribution over the latent space. In our model, it is a multivariate Gaussian distribution $N(0,\\mathbb{I})$.\n","* Let $E(x)$ be the encoder that accepts data points as input and outputs distributions over the latent space $Z$. The produced distribution is denoted $q_\\phi(z|x)$ and is the (approximate) *posterior* distribution. In our model, this is multivariate Gaussian distribution $q_\\phi(z|x) \\sim N(\\mu, diag(\\sigma^2))$, where:\n","    1. $\\phi$ are weights of the encoder network.\n","    2. The Encoder network accepts data points as input and outputs $\\mu$ and $\\sigma$, which are vectors of the same length as latent space. They are used to construct the approximate posterior distribution $q_\\phi(z|x)$.\n","* Let $D(z)$ be the decoder that accepts samples from the latent distribution and output parameters of the likelihood distribution $p_\\theta(x|z)$. In our model, this is the Bernoulli trial per each pixel $p_\\theta(x|z_0) \\sim Bern(p)$, where:\n","    1. $\\theta$ are weights of the decoder network.\n","    2. The decoder network accepts a sample from the posterior distribution $q_\\phi(z|x)$ and outputs p, which is a matrix of the shape of the input image. Each value of the matrix is the parameter $\\pi$ of the Bernoulli trial $Bern(\\pi)$ for the corresponding pixel.\n","    3. Data points are clipped to only contain values 0 and 1 so that the model can be trained in the given setup.\n","\n","The Variational AutoEncoder works by maximizing the Evidence Lower Bound (ELBO):\n","\n","$$ELBO = \\mathbb{E}_{z \\sim q(z|x)} \\big[\\log p_\\theta(x|z)\\big] - \\mathbb{KL}\\big(q_\\phi(z | x) || p(z)\\big).$$\n","\n","Where the first term of the loss is trained via stochastic gradient descent. Whereas, the second term can be calculated analytically in our setup and is equal to the following:\n","\n","$$ \\mathbb{KL}\\big( \\mathcal{N}(\\mu, \\sigma^2) || \\mathcal{N}(0, 1) \\big) = \\frac12 \\big(\\sigma^2 - \\log(\\sigma^2) + \\mu^2 - 1 \\big).$$\n","\n","You do not need to use the formulas above, as the Variational AutoEncoder is already implemented below."]},{"cell_type":"markdown","metadata":{"id":"fmcXQD7zFm6A"},"source":["## Variational AutoEncoder - code\n","The code for VAE is already completed and attached below. Run the code to train the VAE."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"5oaegYX3-Enm","jukit_cell_id":"mIRhZXmXjZ","executionInfo":{"status":"ok","timestamp":1764780083165,"user_tz":-60,"elapsed":18143,"user":{"displayName":"Veronika Nechaieva","userId":"13541061591014079018"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms # type: ignore\n","from torch.utils.data import DataLoader\n","\n","from collections import namedtuple\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"CG4DPj87-Enn","jukit_cell_id":"o6ghXwN1P4","executionInfo":{"status":"ok","timestamp":1764780091400,"user_tz":-60,"elapsed":112,"user":{"displayName":"Veronika Nechaieva","userId":"13541061591014079018"}}},"outputs":[],"source":["batch_size = 1024\n","test_batch_size = 1000\n","epochs = 5\n","lr = 5e-3\n","seed = 1\n","log_interval = 5\n","latent_size = 10"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"6_fkxSGM-Enn","jukit_cell_id":"1fDwZIPWsn","executionInfo":{"status":"ok","timestamp":1764780092525,"user_tz":-60,"elapsed":3,"user":{"displayName":"Veronika Nechaieva","userId":"13541061591014079018"}}},"outputs":[],"source":["use_cuda = torch.cuda.is_available()\n","torch.manual_seed(seed)\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","train_kwargs = {'batch_size': batch_size}\n","test_kwargs = {'batch_size': test_batch_size}\n","if use_cuda:\n","    cuda_kwargs = {'num_workers': 1,\n","                    'pin_memory': True,\n","                    'shuffle': True}\n","    train_kwargs.update(cuda_kwargs)\n","    test_kwargs.update(cuda_kwargs)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"J97S4jqt-Enp","jukit_cell_id":"LHCziTTTb3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764780226480,"user_tz":-60,"elapsed":106163,"user":{"displayName":"Veronika Nechaieva","userId":"13541061591014079018"}},"outputId":"75ec8486-0342-4c62-9f1d-639ae11138f7"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:00<00:00, 24.9MB/s]\n","100%|██████████| 28.9k/28.9k [00:00<00:00, 606kB/s]\n","100%|██████████| 1.65M/1.65M [00:00<00:00, 5.54MB/s]\n","100%|██████████| 4.54k/4.54k [00:00<00:00, 6.56MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 [0/60000 (0%)]\tLoss: 573246.625000\n","Train Epoch: 1 [5120/60000 (8%)]\tLoss: 214195.140625\n","Train Epoch: 1 [10240/60000 (17%)]\tLoss: 181458.328125\n","Train Epoch: 1 [15360/60000 (25%)]\tLoss: 167354.421875\n","Train Epoch: 1 [20480/60000 (34%)]\tLoss: 159629.750000\n","Train Epoch: 1 [25600/60000 (42%)]\tLoss: 149311.187500\n","Train Epoch: 1 [30720/60000 (51%)]\tLoss: 147676.093750\n","Train Epoch: 1 [35840/60000 (59%)]\tLoss: 148970.593750\n","Train Epoch: 1 [40960/60000 (68%)]\tLoss: 143459.125000\n","Train Epoch: 1 [46080/60000 (76%)]\tLoss: 140834.937500\n","Train Epoch: 1 [51200/60000 (85%)]\tLoss: 138298.218750\n","Train Epoch: 1 [56320/60000 (93%)]\tLoss: 133232.031250\n","\n","Test set: Average loss: 130208.9453\n","\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 131565.984375\n","Train Epoch: 2 [5120/60000 (8%)]\tLoss: 130767.710938\n","Train Epoch: 2 [10240/60000 (17%)]\tLoss: 126545.750000\n","Train Epoch: 2 [15360/60000 (25%)]\tLoss: 128815.945312\n","Train Epoch: 2 [20480/60000 (34%)]\tLoss: 128171.843750\n","Train Epoch: 2 [25600/60000 (42%)]\tLoss: 127549.414062\n","Train Epoch: 2 [30720/60000 (51%)]\tLoss: 128705.281250\n","Train Epoch: 2 [35840/60000 (59%)]\tLoss: 129695.718750\n","Train Epoch: 2 [40960/60000 (68%)]\tLoss: 126923.187500\n","Train Epoch: 2 [46080/60000 (76%)]\tLoss: 125953.648438\n","Train Epoch: 2 [51200/60000 (85%)]\tLoss: 124519.968750\n","Train Epoch: 2 [56320/60000 (93%)]\tLoss: 120709.945312\n","\n","Test set: Average loss: 118520.3203\n","\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 121479.171875\n","Train Epoch: 3 [5120/60000 (8%)]\tLoss: 121588.656250\n","Train Epoch: 3 [10240/60000 (17%)]\tLoss: 117324.734375\n","Train Epoch: 3 [15360/60000 (25%)]\tLoss: 120825.906250\n","Train Epoch: 3 [20480/60000 (34%)]\tLoss: 120877.992188\n","Train Epoch: 3 [25600/60000 (42%)]\tLoss: 121060.484375\n","Train Epoch: 3 [30720/60000 (51%)]\tLoss: 122127.328125\n","Train Epoch: 3 [35840/60000 (59%)]\tLoss: 123401.453125\n","Train Epoch: 3 [40960/60000 (68%)]\tLoss: 121610.289062\n","Train Epoch: 3 [46080/60000 (76%)]\tLoss: 120892.226562\n","Train Epoch: 3 [51200/60000 (85%)]\tLoss: 119661.765625\n","Train Epoch: 3 [56320/60000 (93%)]\tLoss: 116400.312500\n","\n","Test set: Average loss: 114050.5625\n","\n","Train Epoch: 4 [0/60000 (0%)]\tLoss: 116155.359375\n","Train Epoch: 4 [5120/60000 (8%)]\tLoss: 117614.976562\n","Train Epoch: 4 [10240/60000 (17%)]\tLoss: 113828.171875\n","Train Epoch: 4 [15360/60000 (25%)]\tLoss: 117113.445312\n","Train Epoch: 4 [20480/60000 (34%)]\tLoss: 116252.851562\n","Train Epoch: 4 [25600/60000 (42%)]\tLoss: 118776.695312\n","Train Epoch: 4 [30720/60000 (51%)]\tLoss: 117994.335938\n","Train Epoch: 4 [35840/60000 (59%)]\tLoss: 120206.375000\n","Train Epoch: 4 [40960/60000 (68%)]\tLoss: 117633.476562\n","Train Epoch: 4 [46080/60000 (76%)]\tLoss: 117467.507812\n","Train Epoch: 4 [51200/60000 (85%)]\tLoss: 116530.304688\n","Train Epoch: 4 [56320/60000 (93%)]\tLoss: 114217.234375\n","\n","Test set: Average loss: 111845.5703\n","\n","Train Epoch: 5 [0/60000 (0%)]\tLoss: 114244.359375\n","Train Epoch: 5 [5120/60000 (8%)]\tLoss: 114976.625000\n","Train Epoch: 5 [10240/60000 (17%)]\tLoss: 111393.898438\n","Train Epoch: 5 [15360/60000 (25%)]\tLoss: 113886.429688\n","Train Epoch: 5 [20480/60000 (34%)]\tLoss: 114368.398438\n","Train Epoch: 5 [25600/60000 (42%)]\tLoss: 115965.265625\n","Train Epoch: 5 [30720/60000 (51%)]\tLoss: 115794.046875\n","Train Epoch: 5 [35840/60000 (59%)]\tLoss: 118059.015625\n","Train Epoch: 5 [40960/60000 (68%)]\tLoss: 116022.718750\n","Train Epoch: 5 [46080/60000 (76%)]\tLoss: 115769.367188\n","Train Epoch: 5 [51200/60000 (85%)]\tLoss: 114236.007812\n","Train Epoch: 5 [56320/60000 (93%)]\tLoss: 112371.757812\n","\n","Test set: Average loss: 110400.0625\n","\n"]}],"source":["class Binarize:\n","    def __call__(self, sample: torch.Tensor) -> torch.Tensor:\n","        return torch.bernoulli(sample)\n","\n","\n","transform = transforms.Compose([transforms.ToTensor(), Binarize()])\n","dataset1 = datasets.MNIST(\"../data\", train=True, download=True, transform=transform)\n","dataset2 = datasets.MNIST(\"../data\", train=False, transform=transform)\n","train_loader = DataLoader(dataset1, **train_kwargs)\n","test_loader = DataLoader(dataset2, **test_kwargs)\n","\n","EncoderOutput = namedtuple(\"EncoderOutput\", [\"mu\", \"sigma\"])\n","\n","\n","class Encoder(nn.Module):\n","    def __init__(self, linear_sizes: list[int], latent_size: int):\n","        super().__init__()\n","        self.layers = nn.ModuleList()\n","        for in_layer_size, out_layer_size in zip(linear_sizes, linear_sizes[1:]):\n","            self.layers.append(nn.Linear(in_layer_size, out_layer_size))\n","            self.layers.append(nn.BatchNorm1d(out_layer_size))\n","            self.layers.append(nn.ReLU())\n","\n","        self.last_layer_mu = nn.Linear(linear_sizes[-1], latent_size)\n","        self.last_layer_sigma = nn.Linear(linear_sizes[-1], latent_size)\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        x = nn.Flatten()(x)\n","        for layer in self.layers:\n","            x = layer(x)\n","\n","        mu = self.last_layer_mu(x)\n","        logsigma = self.last_layer_sigma(x)\n","        return EncoderOutput(mu, torch.log(1 + torch.exp(logsigma)))\n","\n","\n","class Decoder(nn.Module):\n","    def __init__(self, linear_sizes: list[int], output_size: tuple[int]):\n","        super().__init__()\n","        self.layers = nn.ModuleList()\n","        for in_layer_size, out_layer_size in zip(linear_sizes, linear_sizes[1:]):\n","            self.layers.append(nn.Linear(in_layer_size, out_layer_size))\n","            self.layers.append(nn.BatchNorm1d(out_layer_size))\n","            self.layers.append(nn.ReLU())\n","\n","        self.last_layer = nn.Sequential(\n","            nn.Linear(linear_sizes[-1], output_size[0] * output_size[1]), nn.Sigmoid()\n","        )\n","        self.output_size = output_size\n","\n","    def forward(self, z: torch.Tensor) -> torch.Tensor:\n","        for layer in self.layers:\n","            z = layer(z)\n","\n","        x = self.last_layer(z)\n","\n","        x = x.view(-1, 1, *self.output_size)\n","        return x\n","\n","\n","VariationalAutoEncoderOutput = namedtuple(\n","    \"VariationalAutoEncoderOutput\", [\"mu\", \"sigma\", \"p\"]\n",")\n","\n","\n","class VariationalAutoEncoder(nn.Module):\n","    def __init__(\n","        self,\n","        encoder_linear_sizes: list[int],\n","        latent_size: int,\n","        decoder_linear_sizes: list[int],\n","        output_size: tuple[int],\n","    ):\n","        super().__init__()\n","        self.encoder = Encoder(encoder_linear_sizes, latent_size)\n","        self.decoder = Decoder(decoder_linear_sizes, output_size)\n","        self.latent_size = latent_size\n","        self.output_size = output_size\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        encoded = self.encoder(x)\n","\n","        z = torch.normal(0.0, 1.0, size=list(encoded.mu.size())).to(device)\n","        z = (z * encoded.sigma) + encoded.mu\n","\n","        decoded = self.decoder(z)\n","        return VariationalAutoEncoderOutput(encoded.mu, encoded.sigma, decoded)\n","\n","    def sample_latent(self, x: torch.Tensor) -> torch.Tensor:\n","        encoded = self.encoder(x)\n","        z = torch.normal(0.0, 1.0, size=list(encoded.mu.size())).to(device)\n","        z = (z * encoded.sigma) + encoded.mu\n","\n","        return z\n","\n","    def sample(self, sample_size: int, samples=None) -> torch.Tensor:\n","        if samples is None:\n","            samples = torch.normal(0.0, 1.0, size=(sample_size, self.latent_size)).to(\n","                device\n","            )\n","\n","        decoded = self.decoder(samples)\n","        return decoded\n","\n","\n","def KL_gaussian_loss(mu, sigma):\n","    return torch.sum(((sigma * sigma) - (2 * torch.log(sigma)) + (mu * mu) - 1) / 2)\n","\n","\n","def ELBO(x, p, mu, sigma):\n","    BCE = F.binary_cross_entropy(p, x, reduction=\"sum\")\n","    KL = KL_gaussian_loss(mu, sigma)\n","    return BCE + KL\n","\n","\n","def train(\n","    model: nn.Module,\n","    device: torch.device,\n","    train_loader: DataLoader,\n","    optimizer: optim.Optimizer,\n","    epoch: int,\n","    log_interval: int,\n","):\n","    model.train()\n","    for batch_idx, (data, _) in enumerate(train_loader):\n","        data = data.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = ELBO(data, output.p, output.mu, output.sigma)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % log_interval == 0:\n","            print(\n","                \"Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n","                    epoch,\n","                    batch_idx * len(data),\n","                    len(train_loader.dataset),\n","                    100.0 * batch_idx / len(train_loader),\n","                    loss.item(),\n","                )\n","            )\n","\n","\n","def test(model: nn.Module, device: torch.device, test_loader: DataLoader):\n","    model.eval()\n","    test_loss = 0\n","    with torch.no_grad():\n","        for batch_idx, (data, _) in enumerate(test_loader):\n","            data = data.to(device)\n","            output = model(data)\n","            loss = ELBO(data, output.p, output.mu, output.sigma)\n","            test_loss = test_loss + (loss * data.size(0))\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print(\"\\nTest set: Average loss: {:.4f}\\n\".format(test_loss))\n","\n","\n","vae = VariationalAutoEncoder(\n","    [28 * 28, 500, 350], latent_size, [latent_size, 350, 500], (28, 28)\n",")\n","vae.to(device)\n","optimizer = optim.Adam(vae.parameters(), lr=lr)\n","\n","for epoch in range(1, epochs + 1):\n","    train(vae, device, train_loader, optimizer, epoch, log_interval)\n","    test(vae, device, test_loader)"]},{"cell_type":"markdown","metadata":{"id":"7amV1I4oFm6b"},"source":["## Training the Latent Classifier - subtasks:\n","Below are all graded subtasks associated with this exam task:\n","\n","1. Complete the implementation of `ClassificationHead`, which, given a latent vector generated by an `Encoder` for an image $i$ (just the $\\mu$ part), predicts to which class (digit) the image $i$ belongs.\n","2. Complete the implementation of `Classifier`, which, given an input image, first encodes it with a frozen pre-trained `Encoder` and then passes it through the `ClassificationHead` to generate logits for classification.\n","3. Complete the implementation of `train_classifier`, which trains the `Classifier` module. To be more precise, it trains only the `ClassificationHead` of the `Classifier`. So, for an image $i$, given the output of the pre-trained `Encoder` on the image $i$ (just the $\\mu$ part), `ClassificationHead` predicts the class to which the image belongs (which digit is present on the image).\n","\n","Remarks:\n","* To earn all points, your model should achieve an accuracy greater than 90% (see test at the end).\n","* Note that not all variables should be trained, and in particular, no gradients should be propagated throughout the `Encoder`.\n","* Use a proper loss function for training the `Classifier` and select appropriate training parameters to ensure the final accuracy is above 90%.\n","* Do not change the code outside the following blocks\n","```python3\n","#### TODO ####\n","\n","##############\n","````\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uw9teIYtFm6f"},"outputs":[],"source":["class ClassifactionHead(nn.Module):\n","    def __init__(self, latent_size, num_classes):\n","        super().__init__()\n","        #### TODO ####\n","        pass\n","        ##############\n","\n","    def forward(self, x):\n","        #### TODO ####\n","        pass\n","        ##############\n","\n","\n","class Classifier(nn.Module):  # 1pt\n","    def __init__(self, vae, head):\n","        super().__init__()\n","        #### TODO ####\n","        pass\n","        ##############\n","\n","    def forward(self, x):\n","        #### TODO ####\n","        pass\n","        ##############\n","\n","\n","def train_classifier(train_loader, epochs=10, **kwargs):\n","    #### TODO ####\n","    pass\n","    ##############\n","\n","#### TODO ####\n","# Adjust kwargs if needed\n","train_function_kwargs = {}\n","##############\n","\n","classifier = train_classifier(train_loader, **train_function_kwargs)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"laxPPybaFm6n"},"outputs":[],"source":["def test_classifier(classifier):\n","    classifier.eval()\n","    test_loss = 0\n","    with torch.no_grad():\n","        for (data, label) in test_loader:\n","            data = data.to(device)\n","            label = label.to(device)\n","            output = classifier(data)\n","            loss = torch.mean((torch.argmax(output, dim=-1) == label).to(float))\n","            test_loss = test_loss + (loss * data.size(0))\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}\\n'.format(test_loss))\n","    return test_loss\n","\n","assert test_classifier(classifier) > 0.90, 'Classifier not trained well enough'\n"]}],"metadata":{"anaconda-cloud":{},"colab":{"provenance":[]},"kernelspec":{"display_name":"ml","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}